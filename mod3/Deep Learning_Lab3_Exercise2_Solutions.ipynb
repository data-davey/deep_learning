{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkITvwU5zWMu"
   },
   "source": [
    "# Image Classification with PyTorch\n",
    "### *CIFAR100 Dataset*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL4xManXKYtq"
   },
   "source": [
    "# Predicting 100 types of objects (multi-class classification)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The data was originally collected and shared by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
    "\n",
    "Each observation is a color image of size 32 by 32 representing 100 different types of objects such as vehicles, fruits or animals.\n",
    "\n",
    "This dataset is avalaible from PyTorch: [CIFAR100]\n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR100.html)\n",
    "\n",
    "## Objective\n",
    "\n",
    "Our goal is to build a Convolution Neural Network model that can predict accurately the different types of objects from the images.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "This is a guided exercise where some of the code have already been pre-defined. Your task is to fill the remaining part of the code (it will be highlighted with placehoders) to train and evaluate your model.\n",
    "\n",
    "This exercise is split in several parts:\n",
    "1.   Loading and Exploration of the Dataset\n",
    "2.   Preparing the Dataset\n",
    "3.   Defining the CNN Architecture:\n",
    "    - Convolutional layer with 32 kernels of (3,3) and padding = 1\n",
    "    - ReLU as the activation function\n",
    "    - Max pooling of (2,2)\n",
    "    - Convolutional layer with 64 kernels of (3,3) and padding = 1\n",
    "    - ReLU as the activation function\n",
    "    - Max pooling of (2,2)\n",
    "    - Convolutional layer with 128 kernels of (3,3) and padding = 1\n",
    "    - ReLU as the activation function\n",
    "    - Max pooling of (2,2)\n",
    "    - Fully-connected layer of 512 units\n",
    "    - Fully-connected layer of 100 (output) units\n",
    "    - ReLU as the activation function for the hidden layers\n",
    "    - Adam as the optimiser\n",
    "4.   Training and Evaluation of the Model\n",
    "5.   Analysing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh74vJBHN6rW"
   },
   "source": [
    "## Exercise 2 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeiVsyk7N_2k"
   },
   "source": [
    "### 1. Loading and Exploration of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIEx6k4COFKU"
   },
   "source": [
    "**[1.1]** First we need to import the relevant class and libraries that contains the dataset from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "joOwLfqD5Wzh"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8teNk_EOVBe"
   },
   "source": [
    "**[1.2]** Apply transformation using compose class. Use Normalize function of PyTorch (https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) to get data data within a range and reduce skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x49HoApbOVOH"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0TPpRpCPeLP"
   },
   "source": [
    "**[1.3]** Then we will load the CIFAR100 dataset into separate variables: `train_data`, `test_data`. (https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16489,
     "status": "ok",
     "timestamp": 1740792255697,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "fxwd23t9PeWx",
    "outputId": "09b56981-06bf-4163-db2d-31dc5c0cbd5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "train_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V75s-HZiRZ1A"
   },
   "source": [
    "### 2.   Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UZPvkyUReXO"
   },
   "source": [
    "[2.1] We already prepared the dataset in section 1.3 by using Nromalize function for training and testing sets. Now, lets have a look at the maximum value and minimum value of train_data[0][0] and test_data[0][0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1740792255864,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "M0N6wlF_Rj13",
    "outputId": "0335afa1-3d9b-44d0-bfc0-be995f88335b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9922)\n",
      "tensor(1.)\n",
      "tensor(-0.6314)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print(train_data[0][0].min())\n",
    "print(train_data[0][0].max())\n",
    "print(test_data[0][0].min())\n",
    "print(test_data[0][0].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5CDxJopFRIO"
   },
   "source": [
    "**[2.2]** Look at the dimensions of train_data and test_data numpy arrays using the [.size()](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html) method\n",
    "\n",
    "\n",
    "##### Task: Display the dimensions of train_data and test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740792255869,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "7NB0HLB_EVp6",
    "outputId": "808879cd-1747-4bd6-f53a-690aa1a32ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 50000\n",
      "torch.Size([3, 32, 32]) 10000\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print(train_data[0][0].size(), len(train_data))\n",
    "print(test_data[0][0].size(), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ctrhz2QRniP"
   },
   "source": [
    "[2.3] Let's print the details of train data to know the number of data points, transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740792255906,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "VEeX9vhWRnuZ",
    "outputId": "cb29907b-42bd-4db8-d3d0-ccf45a01ec95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR100\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print (train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsIvNcSmRwoA"
   },
   "source": [
    "[2.4] Let's print the details of test data to know the number of data points, transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740792255915,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "7olFZ33WRw2S",
    "outputId": "67708bd5-dba1-43a7-c060-1619b37b1eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR100\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print (test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq2hx9A3SGLZ"
   },
   "source": [
    "### 3.   Defining the Architecture of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZchGVreLSIE5"
   },
   "source": [
    "**[3.1]** Import `torch.nn` as `nn`, `torch.optim` as `optim` and other relevant packages to define the architecture of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DF8OzteoSGjb"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebC6fGVcSVr_"
   },
   "source": [
    "**[3.2]** We will set the seeds for Pytorch in order to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740792255916,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "CKd9HEJySWEZ",
    "outputId": "5f9c3942-3ab1-44d9-a8d4-a9dc16dd8a67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12154a6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjSStDjKSy_1"
   },
   "source": [
    "**[3.3]** Now we will define the model architecture. In this architecture,we will create a class named CNN_CIFAR consists of 3 convolutional layers using the [Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) class from PyTorch. After then we will instantiate 2 fully-connected layers for making the\n",
    "predictions.\n",
    "\n",
    "##### Task:\n",
    "1. Create 3 convolutional layers with the right number of kernels, size of kernel and activation function, Max Pooling layer with [MaxPool2D](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) that will be used after each Conv2D\n",
    "2. Create 2 fully-connected layers and specify the right number of units and activation function\n",
    "\n",
    "Note: the first Conv2D will be the input layer so you will need to specify the input channels.\n",
    "\n",
    "**Task: You need to create 2 fully-connected layers with the relevant number of units and activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hDZFP6vKYfhN"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Define the CNN model\n",
    "class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR, self).__init__()\n",
    "        # ------------------ First Convolutional Block ------------------\n",
    "        # in_channels=3 because CIFAR100 images are in RGB\n",
    "        # out_channels=32 defines how many feature maps this layer will produce\n",
    "        # kernel_size=3 with padding=1 preserves spatial dimensions (32x32) after convolution\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()                      # Activation function\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)      # Reduces image dimension by a factor of 2 (32 x 32 -> 16 x 16)\n",
    "\n",
    "        # ------------------ Second Convolutional Block ------------------\n",
    "        # in_channels=32 from the previous layer, out_channels=64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)      # Reduces image dimension by a factor of 2 (16 x 16 -> 8 x 8)\n",
    "\n",
    "        # ------------------ Third Convolutional Block ------------------\n",
    "        # in_channels=64 from the previous layer, out_channels=128\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)      # Reduces image dimension by a factor of 2 (8 x 8 -> 4 x 4)\n",
    "\n",
    "        # Flatten layer to convert 3D feature maps into a 1D vector\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # ------------------ Fully Connected Layers ------------------\n",
    "        # After 3 rounds of pooling, each dimension is halved thrice: 32 -> 16 -> 8 -> 4\n",
    "        # Hence, the input to the first FC layer is 128 * 4 * 4 = 2048\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 100)  # 100 classes for CIFAR-100\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the first convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Pass through the second convolutional block\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Pass through the third convolutional block\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten the feature maps for the fully connected layers\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Pass through the first fully connected layer with ReLU\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        # Output layer (no activation here since we'll use CrossEntropyLoss)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0hqOUiWWsZh"
   },
   "source": [
    "**[3.4]** Now instantiate the class and save it into a variable named `model'. Now our architecture is ready. Lets print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1740792255956,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "zEe2hqPJWspK",
    "outputId": "47c5d3f6-0cb6-46c6-8bd8-c471bc920859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_CIFAR(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "model = CNN_CIFAR()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6mtZPdeXZjS"
   },
   "source": [
    "### 4. Training and Evaluation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sGY0hsIXap6"
   },
   "source": [
    "**[4.1]** Instantiate a `nn.CrossEntropyLoss()` (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) and save it into a variable called `criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VN1uuXFoXhBp"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDp64CP7XlHL"
   },
   "source": [
    "**[4.2]**  Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1kggcL9uXlQn"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLggIQUrXsuq"
   },
   "source": [
    "**[4.3]**  Now we will call the DataLoader function that iteratively loads data based on batch size, and save it into two different variables called `train_dataloader` and `test_dataloader`. Set the `batch_size` to 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PI8xvsWoXs4T"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9LnBVDHYGro"
   },
   "source": [
    "**[4.4]** **Training:** Now it is time to train our model. Set the `EPOCHS` to 5 and create a for loop that will iterate based on the EPOCHS value. A nested loop is initiated that extracts data and target from dataloader_train and introduce the following logics:\n",
    "- reset the gradients\n",
    "- perform the forward propagation and get the model predictions\n",
    "- calculate the loss between the predictions and the actuals\n",
    "- perform back propagation\n",
    "- update the weights\n",
    "- Count the total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587493,
     "status": "ok",
     "timestamp": 1740792843476,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "wAk145BLYH_h",
    "outputId": "828d3060-9b46-4044-a135-4d2a809966a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 3.580439422136682\n",
      "Epoch 2/5, Loss: 2.7749517473113507\n",
      "Epoch 3/5, Loss: 2.3853881872828353\n",
      "Epoch 4/5, Loss: 2.097533574951884\n",
      "Epoch 5/5, Loss: 1.8507179412085686\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "epochs = 5\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        outputs = model(images) # Forward Propagation to get predicted outcome\n",
    "        loss = criterion(outputs, labels) # Compute the loss\n",
    "        losses.append(loss.detach().numpy()) # Keep track of the losses\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward() # Back propagation\n",
    "        optimizer.step() # Update the weights\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OTfkvpYbNOX"
   },
   "source": [
    "**[4.5]** **Testing:** Now it is time to test our model. Initiate the `model.eval()` along with `torch.no_grad()` to turn off the gradients. Finally calculate the total and correct value. If the predicted output equals the actual output then count the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7gnEMZzGbNhb"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images) # get the predicted outcome\n",
    "        predicted = torch.max(outputs, 1)[1].squeeze()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRhMD7C4bztL"
   },
   "source": [
    "### 5. Analysing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj0DEDQPb0iN"
   },
   "source": [
    "**[5.1]** Let's calculate the `accuracy` of the model by dividing the correct value with the total value and print the `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740792854246,
     "user": {
      "displayName": "William S.",
      "userId": "16708966449686968459"
     },
     "user_tz": -660
    },
    "id": "90c2AlHkb7Ij",
    "outputId": "6290b436-45d2-4296-f743-926e45633bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4088\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK-bHCLSNiB3"
   },
   "source": [
    "After 5 epochs, the performance of the model is still quite low even though we create a deeper CNN model. The reason is the relatively small size of the images (32 by 32). This is not enough for the model to clearly identify relevant patterns for each type of object."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1H_LIpz9JKuK4YWF_-M2E8QFzfublXc1L",
     "timestamp": 1725878150851
    },
    {
     "file_id": "1mPwohjSp4YUTVyuu6kfeTvubB1kkLJfj",
     "timestamp": 1710574036439
    },
    {
     "file_id": "1_uL5ruKnCyBVW5JJaGATDHnwOMPDLKkI",
     "timestamp": 1709544620965
    },
    {
     "file_id": "1m18tdQD7hs5HWtHYLxxEsVt83JUFIFjp",
     "timestamp": 1709338649574
    },
    {
     "file_id": "1feBQkYEdrZDLtUssYeFGlIHWth4aUSwn",
     "timestamp": 1648016790753
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
